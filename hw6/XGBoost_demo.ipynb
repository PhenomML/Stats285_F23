{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adonoho/Stats285_F23/blob/main/hw6/XGBoost_demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Install, Load, and Login to Weights and Biases"
      ],
      "metadata": {
        "id": "fxtXYuf7HeG0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb -qU\n",
        "import wandb\n",
        "wandb.login()"
      ],
      "metadata": {
        "id": "a69cjaixz3a0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load and Login to Google Big Query"
      ],
      "metadata": {
        "id": "WmS4cSgfH5UZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Google Colab\n",
        "from google.cloud import bigquery\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "%load_ext google.colab.data_table"
      ],
      "metadata": {
        "id": "oP_I4kEbIFA0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load packages"
      ],
      "metadata": {
        "id": "e3ZYeO0bHjb5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XSqBv11AaDMY"
      },
      "outputs": [],
      "source": [
        "# load necessary functions\n",
        "\n",
        "# Numpy\n",
        "import numpy as np\n",
        "\n",
        "# Scikit-Learn\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# XGBoost\n",
        "import xgboost as xgb\n",
        "\n",
        "# Pandas\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Load Adult Income Dataset from Google Big Query\n",
        "\n",
        "**In the next cell, find the string `SUID` and replace it with your actual Stanford ID. For example if your SUID were  `adonoho` you would edit in it to read `suid = \"adonoho\"`.**"
      ],
      "metadata": {
        "id": "Pd0P5I_0IMR5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "suid = \"suid\""
      ],
      "metadata": {
        "id": "TUzPt3JAx8ht"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# project_id and table_name are strings\n",
        "# the following function loads the full dataset\n",
        "# using standard SQL selection commands, we can get parts of the dataset also\n",
        "\n",
        "def get_df_from_project(project_id, table_name):\n",
        "  client = bigquery.Client(project=project_id)\n",
        "  query = f\"SELECT * FROM `{table_name}`\"\n",
        "  df = client.query(query).to_dataframe()\n",
        "  return df\n",
        "\n",
        "# Load the adult income dataframe\n",
        "df = get_df_from_project('stanford-stats-285-donoho', 'XYZ.adult_income')"
      ],
      "metadata": {
        "id": "3zdDab5Var47"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preview Data"
      ],
      "metadata": {
        "id": "yosm94l-Igmb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.head() # preview this dataframe"
      ],
      "metadata": {
        "id": "GFSl5hb2YP3k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the datatypes of the columns\n",
        "df.dtypes"
      ],
      "metadata": {
        "id": "UQg2u7mnou1J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Clean Data\n",
        "\n",
        "We need to change all the categorical variables (\"object\"-types) into columns of 0-1 values indicating if an attribute is present.\n",
        "\n",
        "For example, a column with entries \"democrat\", \"republican\", and \"other\" would be changed into *three* columns: in the first, there would be 1's indicating when a row is \"democrat\" and 0's everywhere else; in the second, 1's indicating a row is \"republican\" and 0's everywhere else; in the third, 1's indicating when a row is \"other\" and 0's everywhere else."
      ],
      "metadata": {
        "id": "oo-J-JLCIpVh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select object columns\n",
        "object_cols = df.select_dtypes(include='object').columns\n",
        "\n",
        "# One-hot encode these columns\n",
        "df_encoded = pd.get_dummies(df, columns=object_cols)\n",
        "\n",
        "# Preview\n",
        "df_encoded.head()"
      ],
      "metadata": {
        "id": "ML57O4l4KWw0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create training and test data\n",
        "\n",
        "Create training and testing sets at 80-20 split"
      ],
      "metadata": {
        "id": "AuIy8rgyKu61"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data: All except the last two columns which are 0-1 columns for income\n",
        "X = df_encoded.iloc[:,:-2]\n",
        "\n",
        "# Target: Whether income is > 50K\n",
        "y = df_encoded.iloc[:,-1]\n",
        "\n",
        "# Split into train and test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
      ],
      "metadata": {
        "id": "OVtYTpFgKsqr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training and Logging\n",
        "\n",
        "## Define experiment space to run over\n",
        "`depth` determines the maximum depth of trees in XGBoost.\n",
        "\n",
        "`lambda` is the size of the L2 (ridge) regularization."
      ],
      "metadata": {
        "id": "2eL9lu71LhQc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "depth_list = [6,8,10]\n",
        "lambda_list = [0.25, 0.5, 1, 2, 4]"
      ],
      "metadata": {
        "id": "Ad6AIeOIL7Rj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Run the experiments**"
      ],
      "metadata": {
        "id": "njfye8YGMDhH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run **one setting** *(for illustration)*"
      ],
      "metadata": {
        "id": "EzXqdEwLMveF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "depth = 4\n",
        "lam = 1\n",
        "num_rounds = 100  # Number of boosting rounds\n",
        "\n",
        "model = xgb.XGBClassifier(eval_metric='logloss', n_estimators=num_rounds,\n",
        "                          max_depth = depth, reg_lambda=lam)\n",
        "model.fit(X_train, y_train, eval_set = [(X_train, y_train), (X_test, y_test)], verbose=1)\n",
        "# model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "test_preds = model.predict(X_test)\n",
        "test_predictions = [1 if x > 0.5 else 0 for x in test_preds]\n",
        "test_accuracy = accuracy_score(y_test, test_predictions)\n",
        "print(f\"Test Accuracy: {test_accuracy}\")\n",
        "\n",
        "# Make predictions of training set\n",
        "train_preds = model.predict(X_train)\n",
        "train_predictions = [1 if x > 0.5 else 0 for x in train_preds]\n",
        "train_accuracy = accuracy_score(y_train, train_predictions)\n",
        "print(f\"Train Accuracy: {train_accuracy}\")"
      ],
      "metadata": {
        "id": "tOOlAMqMMV4n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run **all settings**"
      ],
      "metadata": {
        "id": "d4MMYnh5M1yx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "i = 0 # Index of experiments\n",
        "for depth in depth_list:\n",
        "  for lam in lambda_list:\n",
        "\n",
        "    # üêù 1Ô∏è‚É£ Start a new run to track this script\n",
        "    wandb.init(\n",
        "    project=\"xgboost-demo\",\n",
        "    name=f\"experiment_{i}\",\n",
        "\n",
        "    # Track hyperparameters and run metadata\n",
        "    config={\n",
        "    \"lambda\": lam,\n",
        "    \"max_depth\": depth,\n",
        "    \"method\": \"XGBoost\",\n",
        "    \"dataset\": \"adult_income\",\n",
        "    \"epochs\": 100,\n",
        "    })\n",
        "\n",
        "    i += 1\n",
        "\n",
        "    # Train the model\n",
        "    num_rounds = 100  # Number of boosting rounds\n",
        "\n",
        "    model = xgb.XGBClassifier(eval_metric='logloss',\n",
        "                              max_depth = depth, reg_lambda=lam)\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions on the test set\n",
        "    test_preds = model.predict(X_test)\n",
        "    test_predictions = [1 if x > 0.5 else 0 for x in test_preds]\n",
        "    test_accuracy = accuracy_score(y_test, test_predictions)\n",
        "    print(f\"Test Accuracy: {test_accuracy}\")\n",
        "\n",
        "    train_preds = model.predict(X_train)\n",
        "    train_predictions = [1 if x > 0.5 else 0 for x in train_preds]\n",
        "    train_accuracy = accuracy_score(y_train, train_predictions)\n",
        "    print(f\"Train Accuracy: {train_accuracy}\")\n",
        "\n",
        "    # üêù 2Ô∏è‚É£ Log metrics from your script to W&B\n",
        "    wandb.log({\"method\": \"XGBoost\", \"test_err\": 1-test_accuracy, \"train_err\": 1-train_accuracy, \"lambda\":lam, \"depth\": depth})\n",
        "\n",
        "    # Mark the run as finished\n",
        "    wandb.finish()\n"
      ],
      "metadata": {
        "id": "PNOHpVWJXUT2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **CatBoost: Simple Demo**"
      ],
      "metadata": {
        "id": "W2q3chQ9XiBR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install catboost"
      ],
      "metadata": {
        "id": "0gk6X-SbX624"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import catboost\n",
        "\n",
        "# Initialize the CatBoost model for GPU with verbose output\n",
        "cat_model = catboost.CatBoostClassifier(iterations=100)\n",
        "\n",
        "# Fit the model on the training data, using the same data for evaluation\n",
        "# This will print the training loss at each iteration\n",
        "cat_model.fit(X_train, y_train, eval_set=[(X_train, y_train)])\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "y_pred_cat = cat_model.predict(X_test)\n",
        "accuracy_cat = accuracy_score(y_test, y_pred_cat)\n",
        "\n",
        "print(f\"Accuracy with CatBoost: {accuracy_cat}\")"
      ],
      "metadata": {
        "id": "PfzXTzKTXuth"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **LightGBM: Simple Demo**"
      ],
      "metadata": {
        "id": "SPzOifA2YFF2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import lightgbm as lgb\n",
        "\n",
        "# Create an instance of LGBMClassifier\n",
        "lgb_model = lgb.LGBMClassifier(num_boost_round=100)\n",
        "\n",
        "# Train the model with the training data\n",
        "lgb_model.fit(X_train, y_train, eval_set=[(X_train, y_train),(X_test, y_test)], eval_metric='logloss')\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "y_pred_lgb = lgb_model.predict(X_test)\n",
        "accuracy_lgb = accuracy_score(y_test, y_pred_lgb)\n",
        "\n",
        "print(f\"Accuracy with LightGBM: {accuracy_lgb}\")"
      ],
      "metadata": {
        "id": "eV530KYJYpF0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}